<!doctype html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <title>DataDivers</title>
        <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-QWTKZyjpPEjISv5WaRU9OFeRpok6YctnYmDr5pNlyT2bRjXh0JMhjY6hW+ALEwIH" crossorigin="anonymous">
        <style>
            .red-background {
                background-color: #2F539B; /* Custom class for red background */
                color: white; /* White text color */
            }

            .summary {
                background-color: #e0e0eb;
            }

            a:link, a:visited  {
              color: #2F539B;
              text-decoration: none;
              font-weight: bold;
            }

            .section {
                  margin-bottom: 2rem;     
                }

                .section h3 {
                  display: flex;
                  align-items: center;    
                  gap: 0.4em;             
                  margin-top: 0;
                  margin-bottom: 0.6rem; 
                }

                .section h3 .icon {
                  font-size: 1.4em;       
                  line-height: 1;
                }
        </style>

    </head>
  <body>
    <div class="container-fluid">
        <div class="row">
            <div class="col-12 red-background">
                <h1 class="text-center py-3"><span style="color: #f2aac6">DataDivers</span>: Diving into Data Diversity<br>
                    for Fair and Robust NLP</h1> 
            </div>
        </div>
    </div>


   
    <div class="container mt-5">
        <div class="row align-items-center">
           <div class="col-md-9">
                <div class="p-3  rounded summary">
                <h3>Summary</h3>
                <p>
                    Despite great progress in the field of Natural Language Processing (NLP), the field is still
                    struggling to ensure the robustness and fairness of models. So far, NLP has prioritized data
                    size over data quality. Yet there is growing evidence suggesting that the diversity of data, a
                    key dimension of data quality, is crucial for fair and robust NLP models. Many researchers are
                    therefore trying to create more diverse datasets, but there is no clear path for them to follow.
                    Even the fundamental question ‚ÄúHow can we measure the diversity of a dataset? ‚Äù is currently
                    wide open. We still lack the tools and theoretical
                    insights to understand, improve, and leverage data diversity in NLP.
                </p>
                <p>
                    DataDivers will 1) develop a framework to measure data diversity in NLP datasets;
                    2) investigate how data diversity impacts NLP model behavior; and 3) develop novel approaches
                    that harness data diversity for fairer and more robust NLP models. 
                </p>
               
            </div>

            </div>
             <div class="col-md-3">
                <img src="images/datadivers.png" alt="DataDivers ERC Starting grant project" class="img-fluid"> 
            </div> 
        </div>

    
    <div class="container py-3">
        
        
        <div class="section">
          <h3><span class="icon">üë•</span> Team</h3>
          <p><a href="https://www.uu.nl/staff/CSu">Cantao Su</a> (PhD student), Menan Velayuthan (PhD student), <a href="https://annawegmann.github.io/">Anna Wegmann</a> (postdoc), <a href="https://esther2000.github.io/">Esther Ploeger</a> (postdoc).
        </p>
        </div>

        <div class="section">
          <h3><span class="icon">‚ú®</span> Output</h3>
            <p><b>Publications:</b>
                <ul>
                    <li>Nguyen and Ploeger <i><a href="https://aclanthology.org/2025.emnlp-main.445/">We Need to Measure Data Diversity in NLP - Better and Broader</a></i>, EMNLP 2025.</li>
                    <li>Du et al. <i><a href="https://aclanthology.org/2025.acl-long.821/">Disentangling the Roles of Representation and Selection in Data Pruning</a></i>. ACL 2025.</li>
               </ul>
            </p>
            <p>
                <b>Activities:</b> Our team is participating in the 2nd UniDive Training School in Yerevan (2026)!
                    We presented a poster at the Workshop on Diversity in Large Speech and Language Models (Berlin, 2025).
            </p>
        </div>

        <div class="section">
          <h3><span class="icon">ü§ù</span> Contact</h3>
              <p><b>PI:</b> <a href="http://www.dongnguyen.nl">Dong Nguyen</a>. <br>
                    This project is embedded into the <a href="http://nlpsoc.github.io">NLP &amp; Society Lab</a> (headed by dr. Nguyen), part of
                    the <a href="https://www.uu.nl/en/research/ai-data-science/natural-language-processing">Natural Language Processing group</a>
                    at the <a href="https://www.uu.nl/en/organisation/department-of-information-and-computing-sciences">Department of Information and Computing Sciences</a>
                    at 
                    <a href="http://www.uu.nl">Utrecht University</a></b></p>
        </div>

        <div class="section">
          <h3><span class="icon">üèõÔ∏è</span> Funding</h3>
              <p>This 5-year project (2025-2029) is funded with an <a href="https://cordis.europa.eu/project/id/101162980">ERC Starting Grant</a>. </p>

        </div>
    </div>

    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js" integrity="sha384-YvpcrYf0tY3lHB60NNkmXc5s9fDVZLESaAA55NDzOxhy9GkcIdslK1eN7N6jIeHz" crossorigin="anonymous"></script>
  </body>
</html>
